ğŸ§  1. Redes Neuronales Convolucionales (CNN)

Son modelos diseÃ±ados para analizar imÃ¡genes imitando cÃ³mo el cerebro detecta patrones visuales.
Detectan bordes, texturas y formas automÃ¡ticamente sin que tengamos que programarlo.

ğŸ”¹ LeNet (1998)

Uno de los primeros modelos CNN creados por Yann LeCun.

Usado originalmente para reconocer dÃ­gitos escritos a mano (MNIST).

Estructura simple (2 capas convolucionales + 2 capas fully connected).

Ideal para datasets pequeÃ±os y tareas bÃ¡sicas.

ğŸ”¹ AlexNet (2012)

MarcÃ³ un gran avance en visiÃ³n por computadora (ganÃ³ ImageNet 2012).

MÃ¡s profunda que LeNet (8 capas).

Usa ReLU (activaciÃ³n rÃ¡pida) y Dropout (evita sobreajuste).

Ideal para clasificaciÃ³n de imÃ¡genes a gran escala.

ğŸ”¹ VGG (2014)

Se caracteriza por usar bloques de convoluciones 3x3 repetidas.

Modelos conocidos: VGG16 y VGG19 (por la cantidad de capas).

Muy usada por su simplicidad y rendimiento sÃ³lido, aunque consume mucha memoria.

ğŸ”¹ ResNet (2015)

Introduce conexiones residuales, que permiten redes muy profundas (50, 101 o mÃ¡s capas).

Evita el problema de â€œdesvanecimiento del gradienteâ€.

Modelos populares: ResNet50, ResNet101.

Muy usada en Transfer Learning.

ğŸ”¹ Inception (GoogLeNet)

Usa mÃ³dulos Inception, que combinan convoluciones de diferentes tamaÃ±os (1x1, 3x3, 5x5) en paralelo.

Aprende caracterÃ­sticas a distintas escalas.

Muy eficiente en tiempo y precisiÃ³n.

ğŸ”¹ MobileNet

DiseÃ±ada para dispositivos mÃ³viles o de baja potencia.

Usa convoluciones â€œdepthwise separableâ€ (mÃ¡s ligeras).

Ideal para apps en Android, IoT o proyectos con recursos limitados.

ğŸ”¹ EfficientNet (2019)

Optimiza simultÃ¡neamente profundidad, anchura y resoluciÃ³n del modelo.

MÃ¡s precisa y ligera que redes anteriores.

Ideal para proyectos modernos que buscan alto rendimiento con bajo costo computacional.

âš™ï¸ 2. Transfer Learning (Aprendizaje por Transferencia)

Es una tÃ©cnica donde se usa un modelo ya entrenado (por ejemplo, ResNet50 o VGG16) y se ajusta a un nuevo dataset.

Ejemplo: tomar una red pre-entrenada con millones de imÃ¡genes (ImageNet) y adaptarla para clasificar radiografÃ­as o tipos de frutas.

Ventajas:

Requiere menos datos y tiempo.

Mejora la precisiÃ³n con poco entrenamiento adicional.

ğŸ“Š 3. MÃ©todos ClÃ¡sicos

Antes del boom de las CNN, la clasificaciÃ³n de imÃ¡genes se hacÃ­a extrayendo caracterÃ­sticas manualmente y usando algoritmos clÃ¡sicos de machine learning.

ğŸ”¹ k-NN (k-Nearest Neighbors)

Clasifica una imagen comparÃ¡ndola con sus â€œvecinosâ€ mÃ¡s cercanos en el espacio de caracterÃ­sticas.

Simple pero eficaz en datasets pequeÃ±os.

ğŸ”¹ SVM (Support Vector Machine)

Encuentra el â€œhiperplanoâ€ que mejor separa las clases.

Muy Ãºtil para imÃ¡genes con pocas caracterÃ­sticas relevantes.

ğŸ”¹ Random Forest

Usa un conjunto de Ã¡rboles de decisiÃ³n para clasificar imÃ¡genes.

Robusto y fÃ¡cil de usar, aunque menos potente que las CNN para datos complejos.

ğŸ§© TÃ©cnicas de ExtracciÃ³n de CaracterÃ­sticas

Antes de usar algoritmos como SVM o k-NN, era necesario extraer caracterÃ­sticas visuales.

ğŸ”¹ HOG (Histogram of Oriented Gradients)

Describe bordes y direcciones de gradientes en la imagen.

Muy usado para detecciÃ³n de personas o vehÃ­culos.

ğŸ”¹ SIFT (Scale-Invariant Feature Transform)

Detecta puntos clave en la imagen (invariante a escala e iluminaciÃ³n).

Ideal para reconocimiento de objetos.

ğŸ”¹ SURF (Speeded-Up Robust Features)

VersiÃ³n optimizada de SIFT, mÃ¡s rÃ¡pida.

Detecta y describe regiones distintivas en las imÃ¡genes.